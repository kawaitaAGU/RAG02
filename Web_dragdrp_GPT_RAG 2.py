import streamlit as st
import base64
import io
import pandas as pd
from PIL import Image
from openai import OpenAI
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re

# === OpenAI APIã‚­ãƒ¼ã®åˆæœŸåŒ–ï¼ˆSecretsï¼‰ ============================
if "OPENAI_API_KEY" not in st.secrets:
    st.error("OPENAI_API_KEY ãŒæœªè¨­å®šã§ã™ã€‚Streamlitã®Secretsã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# === UIã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ===============================
st.title("ç”»åƒã‹ã‚‰å•é¡Œã‚’èª­ã¿å–ã‚Šã€RAGä»˜ãã§è‡ªå‹•è§£èª¬")

uploaded_img = st.file_uploader("å•é¡Œç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆ.png, .jpgï¼‰", type=["png", "jpg", "jpeg"])
uploaded_excel = st.file_uploader("éŽåŽ»å•Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆ.xlsxã€ä»»æ„ï¼‰", type=["xlsx"])

if uploaded_img:
    # === ç”»åƒã®base64ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ =======================
    if 'b64_img' not in st.session_state:
        image = Image.open(uploaded_img).convert("RGB")
        buffer = io.BytesIO()
        image.save(buffer, format="PNG")
        st.session_state['b64_img'] = base64.b64encode(buffer.getvalue()).decode()

    data_uri = f"data:image/png;base64,{st.session_state['b64_img']}"

    # === GPTã§OCRï¼ˆç”»åƒã‹ã‚‰å•é¡Œæ–‡ã‚’æŠ½å‡ºï¼‰ ===========================
    with st.spinner("ç”»åƒã‹ã‚‰å•é¡Œæ–‡ã‚’æŠ½å‡ºä¸­..."):
        extract_response = client.chat.completions.create(
            model="gpt-4o-2024-11-20",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": data_uri}},
                        {"type": "text", "text": "ã“ã®ç”»åƒã«æ›¸ã‹ã‚Œã¦ã„ã‚‹å•é¡Œæ–‡ã‚’èª­ã¿å–ã£ã¦ãã ã•ã„ã€‚"}
                    ]
                }
            ],
            max_tokens=2000,
            temperature=0.0
        )
        query_text = extract_response.choices[0].message.content.strip()
        st.subheader("ðŸ” æŠ½å‡ºã•ã‚ŒãŸå•é¡Œæ–‡")
        st.text_area("å•é¡Œæ–‡", query_text, height=200)

    # === Excelã‹ã‚‰RAGæŠ½å‡ºï¼ˆã‚ã‚Œã°ï¼‰ ==================================
    rag_text = ""
    if uploaded_excel is not None:
        try:
            with st.spinner("Excelã‹ã‚‰é¡žä¼¼å•é¡Œã‚’æ¤œç´¢ä¸­..."):
                df = pd.read_excel(uploaded_excel)
                corpus, index_to_row = [], []

                for i, row in df.iterrows():
                    for cell in row:
                        if isinstance(cell, str) and len(cell) > 10:
                            corpus.append(cell)
                            index_to_row.append(i)

                if corpus:
                    vectorizer = TfidfVectorizer()
                    X = vectorizer.fit_transform(corpus + [query_text])
                    similarities = cosine_similarity(X[-1], X[:-1])[0]
                    top_indices = similarities.argsort()[-3:][::-1]

                    similar_questions = []
                    for idx in top_indices:
                        row = df.iloc[index_to_row[idx]]
                        text = corpus[idx]
                        choices = [str(cell) for cell in row if isinstance(cell, str) and 5 < len(cell) < 100 and cell != text]
                        correct = next((cell.strip().upper() for cell in row if isinstance(cell, str) and cell.strip().upper() in ['A', 'B', 'C', 'D', 'E']), "")

                        qinfo = f"{text}\né¸æŠžè‚¢:\n" + "\n".join(f"- {c}" for c in choices[:5])
                        if correct:
                            qinfo += f"\næ­£è§£ã¨æ€ã‚ã‚Œã‚‹é¸æŠžè‚¢: {correct}"
                        similar_questions.append(qinfo)

                    rag_text = "\n\n".join(similar_questions)
                    st.subheader("ðŸ“š é¡žä¼¼å•é¡Œï¼ˆRAGï¼‰")
                    for q in similar_questions:
                        st.markdown(f"```\n{q}\n```")
        except Exception as e:
            st.warning(f"Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚RAGãªã—ã§é€²ã‚ã¾ã™ã€‚\n\nè©³ç´°: {e}")
            rag_text = ""

    # === GPTã«è§£èª¬ã‚’ä¾é ¼ï¼ˆè‡ªå‹•å®Ÿè¡Œï¼‰ ================================
    with st.spinner("GPTãŒå•é¡Œã®è§£é‡ˆã¨è§£èª¬ã‚’ç”Ÿæˆä¸­..."):
        prompt_text = (
            f"ä»Šé€ã£ãŸç”»åƒã®å•é¡Œã®è§£èª¬ã‚’ã—ã¦ãã ã•ã„ã€‚æ­£è§£ã‚’æ˜Žç¤ºã—ã€æ ¹æ‹ ã‚’èª¬æ˜Žã—ã¦ãã ã•ã„ã€‚"
            + (f"\nä»¥ä¸‹ã¯éŽåŽ»å•ã‹ã‚‰æŠ½å‡ºã—ãŸé¡žä¼¼å•é¡Œæƒ…å ±ã§ã™ï¼š\n{rag_text}" if rag_text else "")
        )

        response = client.chat.completions.create(
            model="gpt-4o-2024-11-20",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": data_uri}},
                        {"type": "text", "text": prompt_text}
                    ]
                }
            ],
            max_tokens=2000,
            temperature=0.1
        )

        result = response.choices[0].message.content.strip()
        st.subheader("ðŸ’¡ GPTã®è§£èª¬çµæžœï¼ˆæ§‹é€ åŒ–è¡¨ç¤ºï¼‰")

        # === çµæžœã‚’æ§‹é€ åŒ–ã—ã¦è¡¨ç¤º ====================================
        overview = ""
        answer = ""
        choices = {}

        overview_match = re.search(r"ã€?å•é¡Œã®æ¦‚è¦ã€‘?\n?(.*?)(?=\nã€|$)", result, re.DOTALL)
        if overview_match:
            overview = overview_match.group(1).strip()

        answer_match = re.search(r"ã€?æ­£è§£ã€‘?\n?(.*?)(?=\nã€|$)", result, re.DOTALL)
        if answer_match:
            answer = answer_match.group(1).strip()

        choice_matches = re.findall(
            r"^([â‘ -â‘¤1-5a-eA-Eï½-ï½…ï¼¡-ï¼¥])[:ï¼š]?\s*(.+?)(?=\n[â‘ -â‘¤1-5a-eA-Eï½-ï½…ï¼¡-ï¼¥][:ï¼š]|\n*$)",
            result, re.MULTILINE | re.DOTALL
        )
        for label, text in choice_matches:
            choices[label.strip()] = text.strip()

        if overview:
            st.markdown("### ðŸ“ å•é¡Œã®æ¦‚è¦")
            st.markdown(overview)

        if answer:
            st.markdown("### âœ… æ­£è§£")
            st.markdown(answer)

        if choices:
            st.markdown("### ðŸ” é¸æŠžè‚¢ã®è§£èª¬")
            for label, text in choices.items():
                st.markdown(f"**{label}**: {text}")
        else:
            st.markdown("### ðŸ“„ è§£èª¬ï¼ˆåˆ†å‰²ã§ããªã‹ã£ãŸå ´åˆï¼‰")
            st.markdown(result)
