#gpt-4o-2024-11-20
import streamlit as st
import base64
import io
import pandas as pd
from PIL import Image
from openai import OpenAI
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re
from pathlib import Path

# === OpenAI APIã‚­ãƒ¼ã®åˆæœŸåŒ– ========================================
if "OPENAI_API_KEY" not in st.secrets:
    st.error("OPENAI_API_KEY ãŒæœªè¨­å®šã§ã™ã€‚Streamlitã®Secretsã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# === UIã‚¿ã‚¤ãƒˆãƒ«ã¨ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¬„ ===============================
st.title("ç”»åƒã‹ã‚‰å•é¡Œã‚’èª­ã¿å–ã‚Šã€RAGä»˜ãã§è‡ªå‹•è§£èª¬")

uploaded_img = st.file_uploader("å•é¡Œç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆ.png, .jpgï¼‰", type=["png", "jpg", "jpeg"])

if uploaded_img:
    st.session_state.clear()

    st.image(uploaded_img, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ", use_column_width=True)

    image = Image.open(uploaded_img).convert("RGB")
    buffer = io.BytesIO()
    image.save(buffer, format="PNG")
    st.session_state['b64_img'] = base64.b64encode(buffer.getvalue()).decode()

    data_uri = f"data:image/png;base64,{st.session_state['b64_img']}"

    # === GPTã§OCRï¼ˆç”»åƒâ†’ãƒ†ã‚­ã‚¹ãƒˆï¼‰ ===============================
    with st.spinner("ç”»åƒã‹ã‚‰å•é¡Œæ–‡ã‚’æŠ½å‡ºä¸­..."):
        extract_response = client.chat.completions.create(
            model="gpt-4o-2024-11-20",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": data_uri}},
                        {"type": "text", "text": "ã“ã®ç”»åƒã«æ›¸ã‹ã‚Œã¦ã„ã‚‹å•é¡Œæ–‡ã¨é¸æŠè‚¢ã‚’èª­ã¿å–ã£ã¦ãã ã•ã„ã€‚"}
                    ]
                }
            ],
            max_tokens=2000,
            temperature=0.0
        )
        query_text = extract_response.choices[0].message.content.strip()

    # === OCRçµæœã®è¡¨ç¤ºï¼ˆå‚è€ƒï¼‰ =====================================
    with st.expander("ğŸ“ ç”»åƒã‹ã‚‰èª­ã¿å–ã‚‰ã‚ŒãŸå•é¡Œæ–‡ãƒ»é¸æŠè‚¢ï¼ˆOCRçµæœï¼‰", expanded=False):
        st.markdown("ä»¥ä¸‹ã¯ã€ç”»åƒã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸå•é¡Œæ–‡ã¨é¸æŠè‚¢ã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™ï¼ˆå‚è€ƒè¡¨ç¤ºï¼‰ã€‚")
        st.code(query_text, language="markdown")

    # === sample.csv ã‚’èª­ã¿è¾¼ã‚“ã§RAGå‡¦ç† ==========================
    rag_text = ""
    csv_path = Path("sample.csv")
    if not csv_path.exists():
        st.error("sample.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ—ãƒªã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    try:
        with st.spinner("éå»å•ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é¡ä¼¼å•é¡Œã‚’æ¤œç´¢ä¸­..."):
            df = pd.read_csv(csv_path)

            if "å•é¡Œæ–‡" not in df.columns:
                st.error("CSVãƒ•ã‚¡ã‚¤ãƒ«ã« 'å•é¡Œæ–‡' åˆ—ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                st.stop()

            corpus = df["å•é¡Œæ–‡"].fillna("").tolist()
            if not corpus or len(query_text.strip()) < 10:
                st.warning("æŠ½å‡ºã•ã‚ŒãŸå•é¡Œæ–‡ãŒçŸ­ã™ãã‚‹ã‹ã€ç©ºã§ã™ã€‚RAGæ¤œç´¢ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            else:
                vectorizer = TfidfVectorizer()
                X = vectorizer.fit_transform(corpus + [query_text])
                similarities = cosine_similarity(X[-1], X[:-1])[0]
                top_indices = similarities.argsort()[-3:][::-1]

                similar_questions = []
                for idx in top_indices:
                    row = df.iloc[idx]
                    qtext = row["å•é¡Œæ–‡"]
                    choices = [str(row[c]) for c in ['a', 'b', 'c', 'd', 'e'] if c in row and pd.notna(row[c])]
                    correct = str(row["è§£ç­”"]) if "è§£ç­”" in row and pd.notna(row["è§£ç­”"]) else ""

                    qinfo = f"{qtext}\né¸æŠè‚¢:\n" + "\n".join([f"- {c}" for c in choices])
                    if correct:
                        qinfo += f"\næ­£è§£ã¨æ€ã‚ã‚Œã‚‹é¸æŠè‚¢: {correct}"
                    similar_questions.append(qinfo)

                rag_text = "\n\n".join(similar_questions)
                st.subheader("ğŸ“š é¡ä¼¼å•é¡Œï¼ˆRAGï¼‰")
                for q in similar_questions:
                    st.markdown(f"```\n{q}\n```")
    except Exception as e:
        st.warning(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚RAGãªã—ã§é€²ã‚ã¾ã™ã€‚\n\nè©³ç´°: {e}")
        rag_text = ""

    # === GPTã«ã‚ˆã‚‹è§£èª¬ç”Ÿæˆ =========================================
    with st.spinner("GPTãŒè§£èª¬ã‚’ç”Ÿæˆä¸­..."):
        prompt_text = (
            "ä»¥ä¸‹ã®ç”»åƒã«å«ã¾ã‚Œã‚‹å•é¡Œã«å¯¾ã—ã¦ã€æ­£è§£ã¨ãã®æ ¹æ‹ ã‚’èª¬æ˜ã—ã€å„é¸æŠè‚¢ã«å¯¾ã™ã‚‹è§£èª¬ã‚’ã§ã‚ã‚‹èª¿ã§è¨˜è¿°ã›ã‚ˆã€‚"
            + (f"\nä»¥ä¸‹ã¯éå»å•ã‹ã‚‰æŠ½å‡ºã—ãŸé¡ä¼¼å•é¡Œæƒ…å ±ã§ã‚ã‚‹ï¼š\n{rag_text}" if rag_text else "")
        )

        response = client.chat.completions.create(
            model="gpt-4o-2024-11-20",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": data_uri}},
                        {"type": "text", "text": prompt_text}
                    ]
                }
            ],
            max_tokens=2000,
            temperature=0.1
        )

        result = response.choices[0].message.content.strip()
        st.subheader("ğŸ’¡ GPTã®è§£èª¬çµæœï¼ˆæ§‹é€ åŒ–è¡¨ç¤ºï¼‰")

        overview = ""
        answer = ""

        overview_match = re.search(r"ã€?å•é¡Œã®æ¦‚è¦ã€‘?\n?(.*?)(?=\nã€|$)", result, re.DOTALL)
        if overview_match:
            overview = overview_match.group(1).strip()

        answer_match = re.search(r"ã€?æ­£è§£ã€‘?\n?(.*?)(?=\nã€|$)", result, re.DOTALL)
        if answer_match:
            answer = answer_match.group(1).strip()

        if overview:
            st.markdown("### ğŸ“ å•é¡Œã®æ¦‚è¦")
            st.markdown(overview)

        if answer:
            st.markdown("### âœ… æ­£è§£")
            st.markdown(answer)
