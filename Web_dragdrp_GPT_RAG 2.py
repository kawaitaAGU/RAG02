#gpt-4.1
import streamlit as st
import base64
import io
import pandas as pd
from PIL import Image
from openai import OpenAI
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re
from pathlib import Path

# === OpenAI APIã‚­ãƒ¼ã®åˆæœŸåŒ–ï¼ˆSecretsï¼‰ ============================
if "OPENAI_API_KEY" not in st.secrets:
    st.error("OPENAI_API_KEY ãŒæœªè¨­å®šã§ã™ã€‚Streamlitã®Secretsã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# === UIã‚¿ã‚¤ãƒˆãƒ«ã¨ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¬„ ===============================
st.title("ç”»åƒã‹ã‚‰å•é¡Œã‚’èª­ã¿å–ã‚Šã€RAGä»˜ãã§è‡ªå‹•è§£èª¬")

uploaded_img = st.file_uploader("å•é¡Œç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆ.png, .jpgï¼‰", type=["png", "jpg", "jpeg"])

if uploaded_img:
    # === ç”»åƒã‚’ç”»é¢ã«è¡¨ç¤º =========================================
    st.image(uploaded_img, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ", use_column_width=True)

    # === ç”»åƒbase64ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ =============================
    if 'b64_img' not in st.session_state:
        image = Image.open(uploaded_img).convert("RGB")
        buffer = io.BytesIO()
        image.save(buffer, format="PNG")
        st.session_state['b64_img'] = base64.b64encode(buffer.getvalue()).decode()

    data_uri = f"data:image/png;base64,{st.session_state['b64_img']}"

    # === GPTã§OCRï¼ˆç”»åƒâ†’ãƒ†ã‚­ã‚¹ãƒˆï¼‰ ===============================
    with st.spinner("ç”»åƒã‹ã‚‰å•é¡Œæ–‡ã‚’æŠ½å‡ºä¸­..."):
        extract_response = client.chat.completions.create(
            model="gpt-4.1",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": data_uri}},
                        {"type": "text", "text": "ã“ã®ç”»åƒã«æ›¸ã‹ã‚Œã¦ã„ã‚‹å•é¡Œæ–‡ã¨é¸æŠžè‚¢ã‚’èª­ã¿å–ã£ã¦ãã ã•ã„ã€‚"}
                    ]
                }
            ],
            max_tokens=2000,
            temperature=0.0
        )
        query_text = extract_response.choices[0].message.content.strip()
        st.subheader("ðŸ” æŠ½å‡ºã•ã‚ŒãŸå•é¡Œæ–‡")
        st.text_area("å•é¡Œæ–‡", query_text, height=200)

    # === sample.xlsx ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿ ===============================
    rag_text = ""
    excel_path = Path("sample.xlsx")
    if not excel_path.exists():
        st.error("sample.xlsx ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ—ãƒªã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    try:
        with st.spinner("éŽåŽ»å•ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é¡žä¼¼å•é¡Œã‚’æ¤œç´¢ä¸­..."):
            df = pd.read_excel(excel_path)
            corpus, index_to_row = [], []

            for i, row in df.iterrows():
                for cell in row:
                    if isinstance(cell, str) and len(cell) > 10:
                        corpus.append(cell)
                        index_to_row.append(i)

            if corpus:
                vectorizer = TfidfVectorizer()
                X = vectorizer.fit_transform(corpus + [query_text])
                similarities = cosine_similarity(X[-1], X[:-1])[0]
                top_indices = similarities.argsort()[-3:][::-1]

                similar_questions = []
                for idx in top_indices:
                    row = df.iloc[index_to_row[idx]]
                    text = corpus[idx]
                    choices = [str(cell) for cell in row if isinstance(cell, str) and 5 < len(cell) < 100 and cell != text]
                    correct = next((cell.strip().upper() for cell in row if isinstance(cell, str) and cell.strip().upper() in ['A', 'B', 'C', 'D', 'E']), "")

                    qinfo = f"{text}\né¸æŠžè‚¢:\n" + "\n".join(f"- {c}" for c in choices[:5])
                    if correct:
                        qinfo += f"\næ­£è§£ã¨æ€ã‚ã‚Œã‚‹é¸æŠžè‚¢: {correct}"
                    similar_questions.append(qinfo)

                rag_text = "\n\n".join(similar_questions)
                st.subheader("ðŸ“š é¡žä¼¼å•é¡Œï¼ˆRAGï¼‰")
                for q in similar_questions:
                    st.markdown(f"```\n{q}\n```")
    except Exception as e:
        st.warning(f"Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚RAGãªã—ã§é€²ã‚ã¾ã™ã€‚\n\nè©³ç´°: {e}")
        rag_text = ""

    # === GPTã«ã‚ˆã‚‹è§£èª¬ç”Ÿæˆï¼ˆgpt-4.1ï¼‰ ====================
    with st.spinner("GPTãŒè§£èª¬ã‚’ç”Ÿæˆä¸­..."):
        prompt_text = (
            f"ä»Šé€ã£ãŸç”»åƒã®å•é¡Œã®è§£èª¬ã‚’ã—ã¦ãã ã•ã„ã€‚æ­£è§£ã‚’æ˜Žç¤ºã—ã€æ ¹æ‹ ã‚’èª¬æ˜Žã—ã¦ãã ã•ã„ã€‚å„é¸æŠžè‚¢ã«å¯¾ã™ã‚‹è§£èª¬ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚ã§ã€ã‚ã‚‹èª¿ã§æ›¸ã„ã¦ãã ã•ã„ã€‚"
            + (f"\nä»¥ä¸‹ã¯éŽåŽ»å•ã‹ã‚‰æŠ½å‡ºã—ãŸé¡žä¼¼å•é¡Œæƒ…å ±ã§ã™ï¼š\n{rag_text}" if rag_text else "")
        )

        response = client.chat.completions.create(
            model="gpt-4.1",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": data_uri}},
                        {"type": "text", "text": prompt_text}
                    ]
                }
            ],
            max_tokens=2000,
            temperature=0.1
        )

        result = response.choices[0].message.content.strip()
        st.subheader("ðŸ’¡ GPTã®è§£èª¬çµæžœï¼ˆæ§‹é€ åŒ–è¡¨ç¤ºï¼‰")

        # === çµæžœã‚’æ§‹é€ åŒ–ã—ã¦è¡¨ç¤º ================================
        overview = ""
        answer = ""
        choices = {}

        overview_match = re.search(r"ã€?å•é¡Œã®æ¦‚è¦ã€‘?\n?(.*?)(?=\nã€|$)", result, re.DOTALL)
        if overview_match:
            overview = overview_match.group(1).strip()

        answer_match = re.search(r"ã€?æ­£è§£ã€‘?\n?(.*?)(?=\nã€|$)", result, re.DOTALL)
        if answer_match:
            answer = answer_match.group(1).strip()

        choice_matches = re.findall(
            r"^([â‘ -â‘¤1-5a-eA-Eï½-ï½…ï¼¡-ï¼¥])[:ï¼š]?\s*(.+?)(?=\n[â‘ -â‘¤1-5a-eA-Eï½-ï½…ï¼¡-ï¼¥][:ï¼š]|\n*$)",
            result, re.MULTILINE | re.DOTALL
        )
        for label, text in choice_matches:
            choices[label.strip()] = text.strip()

        if overview:
            st.markdown("### ðŸ“ å•é¡Œã®æ¦‚è¦")
            st.markdown(overview)

        if answer:
            st.markdown("### âœ… æ­£è§£")
            st.markdown(answer)

        if choices:
            st.markdown("### ðŸ” é¸æŠžè‚¢ã®è§£èª¬")
            for label, text in choices.items():
                st.markdown(f"**{label}**: {text}")
        else:
            st.markdown("### ðŸ“„ è§£èª¬ï¼ˆåˆ†å‰²ã§ããªã‹ã£ãŸå ´åˆï¼‰")
            st.markdown(result)
