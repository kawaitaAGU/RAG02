import streamlit as st
import base64
import io
import pandas as pd
from PIL import Image
from openai import OpenAI
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# === OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆSecretsã‹ã‚‰ï¼‰ ============================
if "OPENAI_API_KEY" not in st.secrets:
    st.error("OPENAI_API_KEY ãŒæœªè¨­å®šã§ã™ã€‚Streamlitã®Secretsã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# === ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰UI ============================================
st.title("ç”»åƒã‹ã‚‰å•é¡Œã‚’èª­ã¿å–ã‚Šã€éå»å•ã¨ç…§åˆã—ã¦è§£èª¬ã‚’ç”Ÿæˆ")

uploaded_img = st.file_uploader("å•é¡Œç”»åƒï¼ˆ.png, .jpgï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["png", "jpg", "jpeg"])
uploaded_excel = st.file_uploader("éå»å•Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.xlsxï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"])

if uploaded_img and uploaded_excel:
    # === ç”»åƒâ†’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ ==========================================
    image = Image.open(uploaded_img).convert("RGB")
    buffer = io.BytesIO()
    image.save(buffer, format="PNG")
    b64_img = base64.b64encode(buffer.getvalue()).decode()
    data_uri = f"data:image/png;base64,{b64_img}"

    # === GPT OCRã§å•é¡Œæ–‡æŠ½å‡º ============================================
    with st.spinner("ç”»åƒã‹ã‚‰å•é¡Œæ–‡ã‚’æŠ½å‡ºã—ã¦ã„ã¾ã™ï¼ˆGPT Visionï¼‰..."):
        extract_response = client.chat.completions.create(
            model="gpt-4o-2024-11-20",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": data_uri}},
                        {"type": "text", "text": "ã“ã®ç”»åƒã«æ›¸ã‹ã‚Œã¦ã„ã‚‹å•é¡Œæ–‡ã‚’èª­ã¿å–ã£ã¦ãã ã•ã„ã€‚"}
                    ]
                }
            ],
            max_tokens=2000,
            temperature=0.0
        )
        query_text = extract_response.choices[0].message.content.strip()
        st.subheader("ğŸ” æŠ½å‡ºã•ã‚ŒãŸå•é¡Œæ–‡")
        st.text_area("å•é¡Œæ–‡", query_text, height=200)

    # === Excelèª­ã¿è¾¼ã¿ã¨éå»å•æŠ½å‡º =====================================
    with st.spinner("Excelã‹ã‚‰é¡ä¼¼å•é¡Œã‚’æ¤œç´¢ä¸­ï¼ˆTF-IDFï¼‰..."):
        df = pd.read_excel(uploaded_excel)

        corpus = []
        index_to_row = []
        for i, row in df.iterrows():
            for cell in row:
                if isinstance(cell, str) and len(cell) > 10:
                    corpus.append(cell)
                    index_to_row.append(i)

        if not corpus:
            st.error("Excelã‹ã‚‰å•é¡Œæ–‡å€™è£œãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.stop()

        vectorizer = TfidfVectorizer()
        X = vectorizer.fit_transform(corpus + [query_text])
        similarities = cosine_similarity(X[-1], X[:-1])[0]
        top_indices = similarities.argsort()[-3:][::-1]

        similar_questions = []
        for idx in top_indices:
            row = df.iloc[index_to_row[idx]]
            text = corpus[idx]
            choices = [str(cell) for cell in row if isinstance(cell, str) and 5 < len(cell) < 100 and cell != text]
            if not choices:
                choices = ["ï¼ˆé¸æŠè‚¢æƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"]

            correct = ""
            for cell in row:
                if isinstance(cell, str) and cell.strip().upper() in ['A', 'B', 'C', 'D', 'E']:
                    correct = cell.strip().upper()
                    break

            qinfo = f"{text}\né¸æŠè‚¢:\n" + "\n".join(f"- {c}" for c in choices[:5])
            if correct:
                qinfo += f"\næ­£è§£ã¨æ€ã‚ã‚Œã‚‹é¸æŠè‚¢: {correct}"
            similar_questions.append(qinfo)

        rag_text = "\n\n" + "\n\n".join(similar_questions)
        st.subheader("ğŸ“š é¡ä¼¼å•é¡Œï¼ˆRAGï¼‰")
        for q in similar_questions:
            st.markdown(f"```\n{q}\n```")

    # === GPTè§£èª¬ãƒœã‚¿ãƒ³ ================================================
    if st.button("ğŸ“˜ GPTã«è§£èª¬ã‚’ä¾é ¼ã™ã‚‹"):
        with st.spinner("GPTãŒå•é¡Œã®è§£é‡ˆã¨è§£èª¬ã‚’ç”Ÿæˆä¸­..."):
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "image_url", "image_url": {"url": data_uri}},
                            {"type": "text", "text":
                                f"ä»Šé€ã£ãŸç”»åƒã®å•é¡Œã®è§£èª¬ã‚’ã—ã¦ãã ã•ã„ã€‚æ­£è§£ã‚’æ˜ç¤ºã—ã€æ ¹æ‹ ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚\n\n"
                                f"ä»¥ä¸‹ã¯éå»å•ã‹ã‚‰æŠ½å‡ºã—ãŸé¡ä¼¼å•é¡Œæƒ…å ±ã§ã™ï¼š{rag_text}"
                            }
                        ]
                    }
                ],
                max_tokens=2000,
                temperature=0.1
            )
            st.subheader("ğŸ’¡ GPTã®è§£èª¬çµæœ")
            st.markdown(response.choices[0].message.content.strip())
