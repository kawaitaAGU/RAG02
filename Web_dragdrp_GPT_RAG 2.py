# app.py
import streamlit as st
import base64
import io
import pandas as pd
from PIL import Image
from openai import OpenAI
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from pathlib import Path

# OpenAI API ã‚­ãƒ¼ã®ç¢ºèª
if "OPENAI_API_KEY" not in st.secrets:
    st.error("OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Streamlitã®Secretsã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

st.title("ğŸ§  ç”»åƒã‹ã‚‰å•é¡Œã‚’èª­ã¿å–ã‚Šã€é¡ä¼¼å•é¡Œã¨è§£èª¬ã‚’ç”Ÿæˆ")

uploaded_img = st.file_uploader("ğŸ–¼ï¸ å•é¡Œç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["png", "jpg", "jpeg"])
csv_path = Path("sample.csv")

if not csv_path.exists():
    st.error("âŒ sample.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¢ãƒ—ãƒªã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

if uploaded_img:
    st.image(uploaded_img, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ", use_column_width=True)

    # Base64åŒ–ã—ã¦GPTã«é€ä¿¡
    image = Image.open(uploaded_img).convert("RGB")
    buffer = io.BytesIO()
    image.save(buffer, format="PNG")
    b64_img = base64.b64encode(buffer.getvalue()).decode()
    data_uri = f"data:image/png;base64,{b64_img}"

    with st.spinner("ğŸ” å•é¡Œæ–‡ã‚’æŠ½å‡ºä¸­..."):
        extract_response = client.chat.completions.create(
            model="gpt-4o-2024-11-20",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": data_uri}},
                        {"type": "text", "text": "ã‚ãªãŸã¯æ­¯å­¦ç³»ã®å›½å®¶è©¦é¨“ã®å°‚é–€å®¶ã§ã™ã€‚\n"
                "å—é¨“ç”Ÿã«å¯¾ã—ã¦å³å¯†ã‹ã¤æ˜ç¢ºã«ã€å•é¡Œã®æ­£ç­”ã¨ãã®ç†ç”±ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚\n"
                "æ–‡ä½“ã¯ã€ã§ã‚ã‚‹èª¿ã€ã‚’ä½¿ç”¨ã—ã€é¸æŠè‚¢ã”ã¨ã«ç°¡æ½”ãªè§£èª¬ã‚’ã¤ã‘ã¦ãã ã•ã„" "ã“ã®ç”»åƒã«å«ã¾ã‚Œã‚‹å•é¡Œæ–‡ã€é¸æŠè‚¢ã€æ­£è§£ã€å„é¸æŠè‚¢ã®è§£èª¬ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ã§ã‚ã‚‹èª¿ã§æ›¸ã„ã¦ãã ã•ã„ã€‚"}
                    ]
                }
            ],
            max_tokens=2000,
            temperature=0.3
        )
        extracted = extract_response.choices[0].message.content.strip()

    st.subheader("ğŸ“ GPTã«ã‚ˆã‚‹å•é¡Œè§£æ")
    st.markdown(extracted)

    # é¡ä¼¼æ¤œç´¢ã®ãŸã‚ã«csvèª­ã¿è¾¼ã¿
    with st.spinner("ğŸ“š é¡ä¼¼å•é¡Œã‚’æ¤œç´¢ä¸­..."):
        df = pd.read_csv(csv_path)
        if "å•é¡Œæ–‡" not in df.columns:
            st.error("âŒ sample.csv ã« 'å•é¡Œæ–‡' åˆ—ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            st.stop()

        corpus = df["å•é¡Œæ–‡"].fillna("").tolist()
        vectorizer = TfidfVectorizer()
        X = vectorizer.fit_transform(corpus + [extracted])
        sims = cosine_similarity(X[-1], X[:-1])[0]
        top_idx = sims.argsort()[-3:][::-1]

        similar_qs = []
        for i in top_idx:
            row = df.iloc[i]
            q = row["å•é¡Œæ–‡"]
            choices = [str(row.get(c, "")) for c in ['a', 'b', 'c', 'd', 'e']]
            answer = str(row.get("è§£ç­”", ""))
            qtext = f"{q}\né¸æŠè‚¢:\n" + "\n".join([f"- {c}" for c in choices if c]) + f"\næ­£è§£: {answer}"
            similar_qs.append(qtext)

        rag_text = "\n\n".join(similar_qs)

    st.subheader("ğŸ“– é¡ä¼¼å•é¡Œï¼ˆRAGã«ã‚ˆã‚‹æ¤œç´¢ï¼‰")
    for q in similar_qs:
        st.markdown(f"```\n{q}\n```")

    # GPTã«å†é€ä¿¡ã—ã¦ã€é¡ä¼¼å•é¡Œã¨è§£èª¬ã‚’ç”Ÿæˆ
    with st.spinner("ğŸ¤– GPTãŒé¡ä¼¼å•é¡Œã¨è§£èª¬ã‚’ç”Ÿæˆä¸­..."):
        second_prompt = (
            "æ¬¡ã®å†…å®¹ã¯ç”»åƒã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸå•é¡Œã¨éå»ã®é¡ä¼¼å•é¡Œã§ã‚ã‚‹ã€‚\n\n"
            f"{extracted}\n\n"
            f"ä»¥ä¸‹ã¯é¡ä¼¼ã™ã‚‹éå»å•ãƒ‡ãƒ¼ã‚¿ã§ã‚ã‚‹ï¼š\n{rag_text}\n\n"
            "ã“ã®å†…å®¹ã‚’å‚è€ƒã«ã—ã¦ã€å•é¡Œã®æ­£è§£ã¨è§£èª¬ã‚’ã§ã‚ã‚‹èª¿ã§å†æç¤ºã—ã€ã•ã‚‰ã«é¡ä¼¼ã—ãŸæ–°ã—ã„å•é¡Œã‚’3å•ä½œæˆã—ã€å„é¸æŠè‚¢ã«ã¤ã„ã¦ã‚‚ç°¡æ½”ãªè§£èª¬ã‚’åŠ ãˆã¦ãã ã•ã„ã€‚"
        )

        second_response = client.chat.completions.create(
            model="gpt-4o-2024-11-20",
            messages=[{"role": "user", "content": second_prompt}],
            max_tokens=2000,
            temperature=0.5
        )
        result = second_response.choices[0].message.content.strip()

    st.subheader("âœ… GPTã«ã‚ˆã‚‹æœ€çµ‚è§£èª¬ã¨é¡ä¼¼å•é¡Œã®ç”Ÿæˆçµæœ")
    st.markdown(result)
